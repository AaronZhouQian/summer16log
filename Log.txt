Lab Log File for the Work at Theoretical and Emprical Data Science at UCLA in Summer 2016

----
Date: 06/21/2016
----
The code is in the repository https://github.com/AaronZhouQian/tftutorial

Ran tfcnn.py, i.e. the tutorial code for CNN on MNIST, three times with the given
hyperparameters, with testing accuracies of 0.9925, 0.993, 0.9922.

Now we modify the hyperparameters.

#-------------------------------------------------#
Modification 1:
Added one more convolution without adding a max pooling layer.
The reason why we didn't add a max pooling layer is because after the third convolution layer,
the dimension of the images had become 7x7, and I still have to figure out the 
correct dimension of the output if I apply a 2x2 max pooling layer.

The testing accuracies were 0.9923, 0.9912, 0.9929.

The code is at https://github.com/AaronZhouQian/tftutorial/blob/master/3conv_layers.py


#------------------------------------------------#
Modification 2:
Changed the nxn dimension of the filter of the convolutional layers to be n= [3,4,5,6,7]
and ran the algorithm three times for each n=[3,4,5,6,7]

Testing accuracies:
3x3:
0.9920, 0.9908, 0.9918

4x4:
0.9921, 0.9924, 0.9923,

5x5:
0.9883, 0.9926, 0.9921

6x6:
0.9918, 0.9923, 0.9887

7x7:
0.9920, 0.9921, 0.9913

Conclusion: I do not see significant differences across different filter sizes in this range.
Bigger ranges to be tested.

The code is at https://github.com/AaronZhouQian/tftutorial/blob/master/window_hypertfcnn.py

#------------------------------------------------#
Modification 3:

Next, let's blow up the number of output channels.
We have two convolutional layers. We ran the algorithm with the sizes of the filter to be n1xn1, n2xn2 respectively,
where n1,n2=2^i, i=0,1,2,3,4,5,6,7.

The testing accuracies can be seen at https://github.com/AaronZhouQian/tftutorial/blob/master/channel_accuracies.txt

----
Date: 06/21/2016
----

Continuing to modify the parameters
#------------------------------------------------#
Modification 4:
Now we change the stride length (across both width and height of the inputs).

If we change the convolution stride length from 1 to 2, then after the first convolutional layer, since the original image is 28x28, 
the output of the convolutional layer would be 14x14, which would be further reduced to 7x7 by the first max pooling layer.
So let's get rid of the second conv+max_pooling layer first.

We ran the algorithm with stride length l for the convolution layer for l in [2,3,4,5,6]

















